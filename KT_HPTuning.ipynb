{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BCI-and-Neuroergonomics-Lab/3D-MB-CNN/blob/dev/KT_HPTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM_MqVxxcL8T"
      },
      "source": [
        "# Mount Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBKlJ9s7cFIe",
        "outputId": "fa0876d8-3a01-4351-ce9b-f0021a0f1ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Loading your drive so CoLab has access to it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcgFcNcEgxBt"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8gezbiMgv_M",
        "outputId": "bba69bf9-7931-4579-b19b-c2cf5fcd7be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from psutil import virtual_memory\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Softmax\n",
        "from tensorflow.keras.layers import Conv3D, SpatialDropout3D, AveragePooling3D\n",
        "from tensorflow.keras.layers import Conv2D, SpatialDropout2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import DepthwiseConv2D, SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Flatten, Add\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from uuid import uuid4\n",
        "\n",
        "try:\n",
        "  from pandas import DataFrame\n",
        "except ModuleNotFoundError:\n",
        "  !pip install pandas\n",
        "  from pandas import DataFrame\n",
        "\n",
        "try:\n",
        "  import kerastuner as kt\n",
        "except ModuleNotFoundError:\n",
        "  !pip install keras-tuner --upgrade\n",
        "  import kerastuner as kt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1FiSzYpfq0P"
      },
      "source": [
        "# Check For GPU Presence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZIctkfAfqLV",
        "outputId": "ad5be480-dbad-4263-a7b4-476d95da4d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Thu Apr 28 11:55:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    34W / 250W |    375MiB / 16280MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "USE_GPU = True\n",
        "\n",
        "if (USE_GPU):\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "    \n",
        "  ram_gb = virtual_memory().total / 1e9\n",
        "  print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Ff3-uWcN-a"
      },
      "source": [
        "# Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEJwcyYtcOQR",
        "outputId": "aba9ea54-6f67-4faf-c27f-4c53227236d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Checkpointed Models to:\n",
            "/content/drive/MyDrive/BCI-Lab-Drive/Output/Checkpoints/801a0d19-eaa8-4524-ad33-6d941c74779b\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Debugging Information\n",
        "\n",
        "VERBOSE = 1 #@param [0, 1] {type:\"raw\"}\n",
        "\n",
        "#@markdown #High-Level Model Configuration\n",
        "MODE = \"Motor\" #@param [\"Emotion\", \"Motor\"]\n",
        "DIMENSION = '3D' #@param [\"2D\", \"3D\"]\n",
        "BRANCHED = 'MB' #@param [\"MB\", \"SRF\", \"MRF\", \"LRF\"]\n",
        "\n",
        "#@markdown #Low-Level Model Configuration\n",
        "#@markdown ## Model Training Configuration\n",
        "# Options are 'sparse_categorical_crossentropy', 'mean_absolute_error', 'mean_squared_error', or 'categorical_crossentropy'\n",
        "# Can be anything Keras accepts, above are just examples\n",
        "#@markdown Loss function used for model training\n",
        "LOSS_FUNCTION = 'categorical_crossentropy' #@param ['categorical_crossentropy', 'mean_absolute_error', 'sparse_categorical_crossentropy', 'mean_squared_error']\n",
        "\n",
        "# Options are 'Adam' or 'SGD'\n",
        "#@markdown Optimizer used for model training\n",
        "OPTIMIZER_OPTION = \"Adam\" #@param [\"Adam\", \"SGD\"]\n",
        "\n",
        "EPOCHS = 500 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ## Model Type Independent Hyperparameters\n",
        "#@markdown In this section, please enter type None for any variables that should not be declared, any values entered will be fixed during tuning\n",
        "\n",
        "BATCH_SIZE = None #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "INIT_LR = None #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "#@markdown ## 2D Model Hyperparameter Confiuration\n",
        "#@markdown In this section, please enter type None for any variables that should not be declared, any values entered will be fixed during tuning\n",
        "\n",
        "# Parameters for EEGNet2D\n",
        "D_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "SRF_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "MRF_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "LRF_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "F1_2D = None #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "F2_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "CONV_SIZE_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "DROPOUT_RATE_2D =  0.5#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "DROPOUT_TYPE_2D =  \"Dropout\"#@param [\"None\", \"Dropout\", \"SpatialDropout2D\"] {type:\"string\", allow-input: true}\n",
        "if (DROPOUT_TYPE_2D == \"None\"):\n",
        "  DROPOUT_TYPE_2D = None\n",
        "NORM_RATE_2D =  0.25#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "POOLING_1_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "POOLING_2_2D =  None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "#@markdown ## 3D Model Hyperparameter Confiuration\n",
        "#@markdown In this section, please enter type None for any variables that should not be declared, any values entered will be fixed during tuning\n",
        "\n",
        "# Parameters for EEGNet3D\n",
        "D_3D = 4#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "SRF_3D = None #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "MRF_3D = None #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "LRF_3D = None #@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "F1_3D = 16#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "F2_3D = 4#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "CONV_SIZE_3D = None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "DROPOUT_RATE_3D = 0.5#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "DROPOUT_TYPE_3D = 'Dropout'#@param [\"None\"] {type:\"string\", allow-input: true}\n",
        "if (DROPOUT_TYPE_3D == \"None\"):\n",
        "  DROPOUT_TYPE_3D = None\n",
        "NORM_RATE_3D = 0.25#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "POOLING_1_3D = None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "POOLING_2_3D = None#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "SPATIAL_SIZE_3D = 4#@param [\"None\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "\n",
        "#@markdown #Data Settings\n",
        "#@markdown Type of data used for each split between test, train, and validation\n",
        "TRAIN_PROCESSING_STAGE = \"SHUFFLED\" #@param [\"SHUFFLED\", \"AVERAGED\", \"CROPPED\", \"PROCESSED\"]\n",
        "TEST_PROCESSING_STAGE = \"SHUFFLED\" #@param [\"SHUFFLED\", \"AVERAGED\", \"CROPPED\", \"PROCESSED\"]\n",
        "VAL_PROCESSING_STAGE = \"SHUFFLED\" #@param [\"SHUFFLED\", \"AVERAGED\", \"CROPPED\", \"PROCESSED\"]\n",
        "\n",
        "#@markdown Number of classes\n",
        "NUM_CLASSES = 4 #@param [2, 3, 4] {type:\"raw\"}\n",
        "#@markdown Number of samples in each datapoint\n",
        "DEFAULT_SAMPLES = 313 #@param {type:\"integer\"}\n",
        "#@markdown Number of subjects in the Emotion dataset (SEED IV)\n",
        "EMOTION_NUM_SUBJECTS = 15#@param {type:\"integer\"}\n",
        "#@markdown Number of subjects in the Motor dataset (BCICIV_2a)\n",
        "MOTOR_NUM_SUBJECTS = 9#@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Subject to use for emotion analysis\n",
        "EMOTION_SUBJECT_NUM = 1#@param {type:\"integer\"}\n",
        "#@markdown Subject to use for motor analysis\n",
        "MOTOR_SUBJECT_NUM = 7#@param {type:\"integer\"}\n",
        "if (MODE == \"Motor\"):\n",
        "  SUBJECT_NUM = MOTOR_SUBJECT_NUM\n",
        "elif (MODE == \"Emotion\"):\n",
        "  SUBJECT_NUM = EMOTION_SUBJECT_NUM\n",
        "\n",
        "# Results in a shuffle following data creation and when the Kfolds are generated\n",
        "#@markdown Whether or not to shuffle data <br>\n",
        "#@markdown Does not shuffle between splits\n",
        "SHUFFLE = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if (BRANCHED == 'MB'):\n",
        "  BRANCHES = (\"SRF\", \"MRF\", \"LRF\")\n",
        "elif (BRANCHED == 'SRF'):\n",
        "  BRANCHES = (\"SRF\", )\n",
        "elif (BRANCHED == 'MRF'):\n",
        "  BRANCHES = (\"MRF\", )\n",
        "elif (BRANCHED == 'LRF'):\n",
        "  BRANCHES = (\"LRF\", )\n",
        "\n",
        "# ---- Bayesian Variables ------------------------------------------------------\n",
        "#@markdown #Bayesian Tuning Parameters\n",
        "NUM_ITERATIONS = 256 #@param {type:\"integer\"}\n",
        "NUM_CV = 1 #@param [\"None\", 1, 2, 3, 4, 5] {type:\"raw\"}\n",
        "NUM_JOBS = 1 #@param {type:\"integer\"}\n",
        "NUM_POINTS = 1 #@param {type:\"integer\"}\n",
        "OVERWRITE = False #@param {type:\"boolean\"}\n",
        "SEARCH = True #@param {type:\"boolean\"}\n",
        "PROJECT_TAG = \"BranchPooling\" #@param {type:\"string\"}\n",
        "if (PROJECT_TAG != \"\"):\n",
        "  PROJECT_TAG += \"-\"\n",
        "\n",
        "# ---- Directory Stuff ---------------------------------------------------------\n",
        "#@markdown #Data Directories\n",
        "TUNING_DIRECTORY = \"/content/drive/MyDrive/BCI-Lab-Drive/Tuning\" #@param {type:\"string\"}\n",
        "\n",
        "EMOTION_PROCESSED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/SEED/SEED_IV_processed\" #@param {type:\"string\"}\n",
        "EMOTION_CROPPED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/SEED/SEED_IV_cropped\" #@param {type:\"string\"}\n",
        "EMOTION_AVERAGED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/SEED/SEED_IV_averaged\" #@param {type:\"string\"}\n",
        "EMOTION_SHUFFLED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/SEED/SEED_IV_shuffled\" #@param {type:\"string\"}\n",
        "\n",
        "EMOTION_DIR_DICT = {\"PROCESSED\": EMOTION_PROCESSED_DIR, \"CROPPED\": EMOTION_CROPPED_DIR, \"AVERAGED\": EMOTION_AVERAGED_DIR, \"SHUFFLED\": EMOTION_SHUFFLED_DIR}\n",
        "\n",
        "MOTOR_PROCESSED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/BCICIV_2a/BCICIV_2a_processed\" #@param {type:\"string\"}\n",
        "MOTOR_CROPPED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/BCICIV_2a/BCICIV_2a_cropped\" #@param {type:\"string\"}\n",
        "MOTOR_AVERAGED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/BCICIV_2a/BCICIV_2a_averaged\" #@param {type:\"string\"}\n",
        "MOTOR_SHUFFLED_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Datasets/BCICIV_2a/BCICIV_2a_shuffled\" #@param {type:\"string\"}\n",
        "\n",
        "MOTOR_DIR_DICT = {\"PROCESSED\": MOTOR_PROCESSED_DIR, \"CROPPED\": MOTOR_CROPPED_DIR, \"AVERAGED\": MOTOR_AVERAGED_DIR, \"SHUFFLED\": MOTOR_SHUFFLED_DIR}\n",
        "\n",
        "PROCESSED_SUFFIX = \"_processed.npy\" #@param {type:\"string\"}\n",
        "CROPPED_SUFFIX = \"_cropped.npy\" #@param {type:\"string\"}\n",
        "AVERAGED_SUFFIX = \"_averaged.npy\" #@param {type:\"string\"}\n",
        "SHUFFLED_SUFFIX = \"_shuffled.npy\" #@param {type:\"string\"}\n",
        "\n",
        "SUFFIX_DICT = {\"PROCESSED\": PROCESSED_SUFFIX, \"CROPPED\": CROPPED_SUFFIX, \"AVERAGED\": AVERAGED_SUFFIX, \"SHUFFLED\": SHUFFLED_SUFFIX}\n",
        "\n",
        "TRAIN_DIR_APPEND = \"train/\" #@param {type:\"string\"}\n",
        "TEST_DIR_APPEND = \"test/\" #@param {type:\"string\"}\n",
        "VAL_DIR_APPEND = \"val/\" #@param {type:\"string\"}\n",
        "\n",
        "if (MODE == 'Emotion'):\n",
        "  try:\n",
        "    TRAIN_DIR = EMOTION_DIR_DICT[TRAIN_PROCESSING_STAGE]\n",
        "    TRAIN_SUFFIX = SUFFIX_DICT[TRAIN_PROCESSING_STAGE]\n",
        "\n",
        "    TEST_DIR = EMOTION_DIR_DICT[TEST_PROCESSING_STAGE]\n",
        "    TEST_SUFFIX = SUFFIX_DICT[TEST_PROCESSING_STAGE]\n",
        "\n",
        "    VAL_DIR = EMOTION_DIR_DICT[VAL_PROCESSING_STAGE]\n",
        "    VAL_SUFFIX = SUFFIX_DICT[VAL_PROCESSING_STAGE]\n",
        "\n",
        "  except KeyError:\n",
        "    raise Exception(\"Invalid Data Processing Stage, please specify 'PROCESSED', 'CROPPED', 'AVERAGED', or 'SHUFFLED'.\")\n",
        "\n",
        "  DISPLAY_LABELS = ['Neutral', 'Sad', 'Fear', 'Happy']\n",
        "\n",
        "elif (MODE == 'Motor'):\n",
        "  try:\n",
        "    TRAIN_DIR = MOTOR_DIR_DICT[TRAIN_PROCESSING_STAGE]\n",
        "    TRAIN_SUFFIX = SUFFIX_DICT[TRAIN_PROCESSING_STAGE]\n",
        "\n",
        "    TEST_DIR = MOTOR_DIR_DICT[TEST_PROCESSING_STAGE]\n",
        "    TEST_SUFFIX = SUFFIX_DICT[TEST_PROCESSING_STAGE]\n",
        "\n",
        "    VAL_DIR = MOTOR_DIR_DICT[VAL_PROCESSING_STAGE]\n",
        "    VAL_SUFFIX = SUFFIX_DICT[VAL_PROCESSING_STAGE]\n",
        "    \n",
        "  except KeyError:\n",
        "    raise Exception(\"Invalid Data Processing Stage, please specify 'PROCESSED', 'CROPPED', 'AVERAGED', or 'SHUFFLED'.\")\n",
        "\n",
        "  DISPLAY_LABELS = ['Left', 'Right', 'Foot', 'Tongue']\n",
        "\n",
        "else:\n",
        "  raise Exception(\"Invalid Data Mode, please specify 'Emotion' or 'Motor'.\")\n",
        "\n",
        "if (OPTIMIZER_OPTION == 'Adam'):\n",
        "  OPTIMIZER = tf.keras.optimizers.Adam\n",
        "elif (OPTIMIZER_OPTION == 'SGD'):\n",
        "  OPTIMIZER = tf.keras.optimizers.SGD\n",
        "else:\n",
        "  raise Exception(\"Invalid Optimizer Option, please specify 'Adam' or 'SGD'.\")\n",
        "  \n",
        "DIM_3D_SUFFIX = \"_3d/\"\n",
        "DIM_2D_SUFFIX = \"_2d/\"\n",
        "\n",
        "if (DIMENSION == '3D'):\n",
        "  TRAIN_DIR = TRAIN_DIR + DIM_3D_SUFFIX + TRAIN_DIR_APPEND\n",
        "  TEST_DIR = TEST_DIR + DIM_3D_SUFFIX + TEST_DIR_APPEND\n",
        "  VAL_DIR = VAL_DIR + DIM_3D_SUFFIX + VAL_DIR_APPEND\n",
        "elif (DIMENSION == '2D'):\n",
        "  TRAIN_DIR = TRAIN_DIR + DIM_2D_SUFFIX + TRAIN_DIR_APPEND\n",
        "  TEST_DIR = TEST_DIR + DIM_2D_SUFFIX + TEST_DIR_APPEND\n",
        "  VAL_DIR = VAL_DIR + DIM_2D_SUFFIX + VAL_DIR_APPEND\n",
        "else:\n",
        "  raise Exception(\"Invalid Dimension, please specify '3D' or '2D'.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Metrics\n",
        "\n",
        "#@markdown #Metrics\n",
        "\n",
        "ACCURACY_METRIC = True #@param {type:\"boolean\"}\n",
        "PRECISION_METRIC = True #@param {type:\"boolean\"}\n",
        "RECALL_METRIC = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #Callbacks\n",
        "\n",
        "# Epoch End Callback\n",
        "#@markdown Custom epoch end message\n",
        "EPOCH_END = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Profiling Callback\n",
        "#@markdown TensorBoard Profiling\n",
        "PROFILING = False #@param {type:\"boolean\"}\n",
        "PROFILING_OUT_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Output/TensorBoard/\"#@param {type:\"string\"}\n",
        "\n",
        "# Early Stopping Callback\n",
        "#@markdown Early Stopping\n",
        "EARLY_STOPPING = True #@param {type:\"boolean\"}\n",
        "EARLY_STOPPING_PATIENCE = 50#@param {type:\"integer\"}\n",
        "\n",
        "# Model Checkpointing Callback\n",
        "#@markdown Model Checkpointing\n",
        "MODEL_CHECKPOINTING = False #@param {type:\"boolean\"}\n",
        "CHECKPOINT_OUT_DIR = \"/content/drive/MyDrive/BCI-Lab-Drive/Output/Checkpoints/\"#@param {type:\"string\"}\n",
        "CHECKPOINT_OUT_DIR += str(uuid4())\n",
        "print(\"Saving Checkpointed Models to:\\n\" + CHECKPOINT_OUT_DIR)\n",
        "\n",
        "# Live Plot\n",
        "#@markdown Live Training Plot\n",
        "# Supported values include 'Loss', 'Accuracy', and 'F1-Score'\n",
        "# These values will override the above metrics, as they must be included for plot\n",
        "LIVE_PLOTTING = False #@param {type:\"boolean\"}\n",
        "PLOT_METRIC = 'Accuracy' #@param [\"Accuracy\", \"Loss\", \"F1-Score\"] {type:\"string\"}\n",
        "BAD_PLOT_METRIC = \"Unimplemented Plot Metric, please check the value of constant 'PLOT_METRIC'.\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBVGjRK__-nF"
      },
      "source": [
        "# Callbacks & Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrHaEeQ4uizX"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNGtdvq4ukV4"
      },
      "outputs": [],
      "source": [
        "METRICS = []\n",
        "METRIC_NAMES = []\n",
        "\n",
        "if (ACCURACY_METRIC or PLOT_METRIC == 'Accuracy'):\n",
        "  METRICS.append(tf.keras.metrics.CategoricalAccuracy(name='Accuracy'))\n",
        "  METRIC_NAMES.append('Accuracy')\n",
        "\n",
        "if (PRECISION_METRIC or PLOT_METRIC == 'F1-Score'):\n",
        "  METRICS.append(tf.keras.metrics.Precision(name='Precision'))\n",
        "  METRIC_NAMES.append('Precision')\n",
        "\n",
        "if (RECALL_METRIC or PLOT_METRIC == 'F1-Score'):\n",
        "  METRICS.append(tf.keras.metrics.Recall(name='Recall'))\n",
        "  METRIC_NAMES.append('Recall')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqSnhS3DulYc"
      },
      "source": [
        "## Callbacks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_GUZchkJUzq"
      },
      "source": [
        "### Keras Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xc6IbHde4ce"
      },
      "outputs": [],
      "source": [
        "class ModifiedEpochEnd(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, metrics=('loss', 'acc'), metric_names=('Loss', 'Accuracy')):\n",
        "    self.metrics = metrics\n",
        "    self.metric_names = metric_names\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print(\"Finished epoch {}:\".format(epoch+1))\n",
        "\n",
        "    print(\"{:<12} {:<10} {:<10}\".format(\"Metric\", \"Training\", \"Validation\"))\n",
        "    for metric_name in self.metric_names:\n",
        "      print(\"{:<12} {:<10.3f} {:<10.3f}\".format(metric_name, logs[metric_name], logs['val_'+metric_name]))\n",
        "    print(\"\") # Forcing newline\n",
        "  \n",
        "  def on_train_end(self, logs=None):\n",
        "    print(\"\\nTraining Finished\")\n",
        "\n",
        "class LessInfoEpochEnd(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.best_epoch = None\n",
        "    self.best_loss = None\n",
        "    self.best_val_loss = None\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    val_loss = logs['val_loss']\n",
        "    if (self.best_val_loss is None or val_loss < self.best_val_loss):\n",
        "      self.best_epoch = epoch+1\n",
        "      self.best_loss = logs['loss']\n",
        "      self.best_val_loss = val_loss\n",
        "    output = \"\\rFinished Epoch {}: Loss/Val - {:.3}/{:.3}\\tBest Epoch {}: Loss/Val - {:.3}/{:.3}\".format(epoch+1, logs['loss'], logs['val_loss'], self.best_epoch, self.best_loss, self.best_val_loss)\n",
        "    print(output, end='')\n",
        "\n",
        "class PlotLosses(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.epoch_num = 1\n",
        "        self.x = []\n",
        "        self.plot_metric = []\n",
        "        self.plot_val_metric = []\n",
        "\n",
        "        self.best_epoch = None\n",
        "        self.best_val_metric = None\n",
        "        self.best_metric = None\n",
        "\n",
        "        self.hdisplay = display.display(\"\", display_id=True)\n",
        "        tmp = plt.ion()\n",
        "\n",
        "        self.fig = plt.figure()\n",
        "        self.ax = self.fig.add_subplot(111)\n",
        "        self.ax.set_xlabel('Epoch')\n",
        "        self.ax.set_ylabel(PLOT_METRIC)\n",
        "        self.ax.set_title(\"Training Performance\")\n",
        "        self.caption = plt.figtext(0.5, -0.1, '', wrap=True, horizontalalignment='center', fontsize=12)\n",
        "        plt.ylim((0, 1))\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.epoch_num)\n",
        "        if (PLOT_METRIC == 'Accuracy'):\n",
        "          metric = logs.get('Accuracy')\n",
        "          val_metric = logs.get('val_Accuracy')\n",
        "          if (self.best_val_metric is None or val_metric > self.best_val_metric):\n",
        "            self.best_epoch = self.epoch_num\n",
        "            self.best_metric = metric\n",
        "            self.best_val_metric = val_metric\n",
        "          self.plot_metric.append(metric)\n",
        "          self.plot_val_metric.append(val_metric)\n",
        "        elif (PLOT_METRIC == 'Loss'):\n",
        "          metric = logs.get('loss')\n",
        "          val_metric = logs.get('val_loss')\n",
        "          if (self.best_val_metric is None or val_metric < self.best_val_metric):\n",
        "            self.best_epoch = self.epoch_num\n",
        "            self.best_metric = metric\n",
        "            self.best_val_metric = val_metric\n",
        "          self.plot_metric.append(metric)\n",
        "          self.plot_val_metric.append(val_metric)\n",
        "        elif (PLOT_METRIC == 'F1-Score'):\n",
        "          metric = self.compute_f1(logs.get('Precision'), logs.get('Recall'))\n",
        "          val_metric = self.compute_f1(logs.get('val_Precision'), logs.get('val_Recall'))\n",
        "          if (self.best_val_metric is None or val_metric > self.best_val_metric):\n",
        "            self.best_epoch = self.epoch_num\n",
        "            self.best_metric = metric\n",
        "            self.best_val_metric = val_metric\n",
        "          self.plot_metric.append(metric)\n",
        "          self.plot_val_metric.append(val_metric)\n",
        "        else:\n",
        "          raise Exception(BAD_PLOT_METRIC)\n",
        "        self.epoch_num += 1\n",
        "\n",
        "        caption_txt = \"Best Epoch\\nEpoch {} - {}: {:.3} - Val {}: {:.3}\".format(self.best_epoch, PLOT_METRIC, self.best_metric, PLOT_METRIC, self.best_val_metric)\n",
        "        self.caption.set(text=caption_txt)\n",
        "        self.ax.plot(self.x, self.plot_metric, 'r', label=PLOT_METRIC if epoch == 0 else \"\")\n",
        "        self.ax.plot(self.x, self.plot_val_metric, 'b', label=\"Val \" + PLOT_METRIC if epoch == 0 else \"\")\n",
        "        self.fig.legend()\n",
        "\n",
        "        self.hdisplay.update(self.fig)\n",
        "      \n",
        "    def on_train_end(self, logs):\n",
        "        plt.close()\n",
        "\n",
        "    def compute_f1(self, precision, recall):\n",
        "      if (precision == 0 and recall == 0):\n",
        "        return 0\n",
        "      return (2*precision*recall)/(precision+recall)\n",
        "\n",
        "EpochEndCallback = LessInfoEpochEnd()\n",
        "TensorBoardCallback = tf.keras.callbacks.TensorBoard(log_dir=PROFILING_OUT_DIR)\n",
        "EarlyStoppingCallback = tf.keras.callbacks.EarlyStopping(patience=EARLY_STOPPING_PATIENCE, verbose=VERBOSE)\n",
        "ModelCheckpointCallback = tf.keras.callbacks.ModelCheckpoint(CHECKPOINT_OUT_DIR, verbose=VERBOSE, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "CALLBACKS = []\n",
        "if (EPOCH_END):\n",
        "    CALLBACKS.append(LessInfoEpochEnd)\n",
        "if (PROFILING):\n",
        "    CALLBACKS.append(TensorBoardCallback)\n",
        "if (EARLY_STOPPING):\n",
        "    CALLBACKS.append(EarlyStoppingCallback)\n",
        "if (MODEL_CHECKPOINTING):\n",
        "    CALLBACKS.append(ModelCheckpointCallback)\n",
        "if (LIVE_PLOTTING):\n",
        "    CALLBACKS.append(PlotLosses())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmTy46y3JXJW"
      },
      "source": [
        "### Skopt Callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgSNdHHeJZgv"
      },
      "outputs": [],
      "source": [
        "# callback handler\n",
        "def bayes_callback(optim_result):\n",
        "    score = -optim_result['fun']\n",
        "    print(\"\\nBest Score: %s\\n\" % score)\n",
        "    if score >= 0.90:\n",
        "        print('Model Achieved Accuracy of 90%, stopping')\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSTzkAUFfhso"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSC2MX9f0Z0",
        "outputId": "9b2d80d9-0edd-4558-a71b-c411da29ec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X Training Data:\n",
            "(3450, 7, 6, 313)\n",
            "Shape of Y Training Data\n",
            "(3450, 4)\n",
            "Shape of X Test Data:\n",
            "(1150, 7, 6, 313)\n",
            "Shape of Y Test Data\n",
            "(1150, 4)\n",
            "Shape of X Validation Data:\n",
            "(1160, 7, 6, 313)\n",
            "Shape of Y Validation Data\n",
            "(1160, 4)\n"
          ]
        }
      ],
      "source": [
        "def load_data(data_dir, data_suff, subject):\n",
        "  x = np.load(data_dir + \"A0\" + str(subject) + \"D\" + data_suff, encoding='latin1', allow_pickle=True)\n",
        "  y = np.load(data_dir + \"A0\" + str(subject) + \"K\" + data_suff, encoding='latin1', allow_pickle=True)\n",
        "  return x, y\n",
        "\n",
        "def select_classes(X, Y, N):\n",
        "  inds = np.full((X.shape[0]), False)\n",
        "  for i in range(N):\n",
        "    inds = np.bitwise_or(inds, Y[:, i] == 1)\n",
        "  X_new, Y_new = X[inds], Y[inds]\n",
        "  for i in range(Y.shape[1], N, -1):\n",
        "    Y_new = np.delete(Y_new, i-1, axis=1)\n",
        "  return X_new, Y_new\n",
        "\n",
        "# Training Data\n",
        "X_train, Y_train = load_data(TRAIN_DIR, TRAIN_SUFFIX, SUBJECT_NUM)\n",
        "\n",
        "# Test Data\n",
        "X_test, Y_test = load_data(TEST_DIR, TEST_SUFFIX, SUBJECT_NUM)\n",
        "\n",
        "# Validation Data\n",
        "X_val, Y_val = load_data(VAL_DIR, VAL_SUFFIX, SUBJECT_NUM)\n",
        "\n",
        "if (SHUFFLE):\n",
        "  # Training Data\n",
        "  p = np.random.permutation(X_train.shape[0])\n",
        "  X_train = X_train[p]\n",
        "  Y_train = Y_train[p]\n",
        "  \n",
        "  # Test Data\n",
        "  p = np.random.permutation(X_test.shape[0])\n",
        "  X_test = X_test[p]\n",
        "  Y_test = Y_test[p]\n",
        "  \n",
        "  # Validation Data\n",
        "  p = np.random.permutation(X_val.shape[0])\n",
        "  X_val = X_val[p]\n",
        "  Y_val = Y_val[p]\n",
        "\n",
        "if (X_test.shape[-1] != X_train.shape[-1]):\n",
        "  if (DIMENSION == '3D'):\n",
        "    X_test = X_test[:, :, :, :X_train.shape[-1]]\n",
        "  elif (DIMENSION == '2D'):\n",
        "    X_test = X_test[:, :, :X_train.shape[-1]]\n",
        "\n",
        "if (X_val.shape[-1] != X_train.shape[-1]):\n",
        "  if (DIMENSION == '3D'):\n",
        "    X_val = X_val[:, :, :, :X_train.shape[-1]]\n",
        "  elif (DIMENSION == '2D'):\n",
        "    X_val = X_val[:, :, :X_train.shape[-1]]\n",
        "\n",
        "X_train, Y_train = select_classes(X_train, Y_train, NUM_CLASSES)\n",
        "X_test, Y_test = select_classes(X_test, Y_test, NUM_CLASSES)\n",
        "X_val, Y_val = select_classes(X_val, Y_val, NUM_CLASSES)\n",
        "\n",
        "print(\"Shape of X Training Data:\")\n",
        "print(X_train.shape)\n",
        "print(\"Shape of Y Training Data\")\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(\"Shape of X Test Data:\")\n",
        "print(X_test.shape)\n",
        "print(\"Shape of Y Test Data\")\n",
        "print(Y_test.shape)\n",
        "\n",
        "print(\"Shape of X Validation Data:\")\n",
        "print(X_val.shape)\n",
        "print(\"Shape of Y Validation Data\")\n",
        "print(Y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRXrWTYxcpxj"
      },
      "source": [
        "# Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQNQJlArCeSo"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alhcY7bkGSJI"
      },
      "source": [
        "### 3D Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUdWjMVo-g6r"
      },
      "outputs": [],
      "source": [
        "def EEGNet3D(nb_classes, XDim = 7, YDim = 6, Samples = 240, spatialSize=2, dropoutRate = 0.5, smallKernLength = 64, mediumKernLength = 96, largeKernLength = 160, F1 = 8, D = 2, F2 = 16, norm_rate = 0.15, dropoutType = 'Dropout', branches = (\"SRF\", \"MRF\", \"LRF\"), pooling1 = 4, pooling2 = 8, convSize = 16):\n",
        "\tif dropoutType == 'SpatialDropout3D':\n",
        "\t\tdropoutType = SpatialDropout3D\n",
        "\telif dropoutType == 'Dropout':\n",
        "\t\tdropoutType = Dropout\n",
        "\telse:\n",
        "\t\traise ValueError('dropoutType must be one of SpatialDropout3D or Dropout, passed as a string.')\n",
        "    \n",
        "\t# This is dumb, but I can't think of a better way while allowing automatic hp tuning\n",
        "\t# Resolves the constraint that F2 must be a factor of the product of F1 and D\n",
        "\t# Not aware of a way to imply this relationship to KerasTuner parameter spaces\n",
        "\tf2_cands = []\n",
        "\tfor i in range(1, D*F1+1):\n",
        "\t\tif ((D * F1) % i == 0):\n",
        "\t\t\tf2_cands.append(i)\n",
        "\tif (F2 >= len(f2_cands)):\n",
        "\t\tF2 = f2_cands[-1]\n",
        "\telse:\n",
        "\t\tF2 = f2_cands[F2]\n",
        "\n",
        "\tinput1 = Input(shape = (XDim, YDim, Samples, 1))\n",
        "\t\n",
        "\tadd_params = []\n",
        "\tif (\"SRF\" in branches):\n",
        "\t\tSRF_branch = EEGNet3D_Branch(nb_classes, XDim, YDim, Samples, spatialSize, dropoutRate, smallKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "\t\tadd_params.append(SRF_branch)\n",
        "\tif (\"MRF\" in branches):\n",
        "\t\tMRF_branch = EEGNet3D_Branch(nb_classes, XDim, YDim, Samples, spatialSize, dropoutRate, mediumKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "\t\tadd_params.append(MRF_branch)\n",
        "\tif (\"LRF\" in branches):\n",
        "\t\tLRF_branch = EEGNet3D_Branch(nb_classes, XDim, YDim, Samples, spatialSize, dropoutRate, largeKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "\t\tadd_params.append(LRF_branch)\n",
        "\n",
        "\tif (len(add_params) > 1):\n",
        "\t\tfinal = Add()(add_params)\n",
        "\telse:\n",
        "\t\tfinal = add_params[0]\n",
        "\n",
        "\tsoftmax = Activation('softmax', name = 'softmax')(final)\n",
        "        \n",
        "\treturn Model(inputs=input1, outputs=softmax)\n",
        "\n",
        "def EEGNet3D_Branch(nb_classes, XDim, YDim, Samples, spatialSize, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, block):\n",
        "\tblock1 = Conv3D(F1, (spatialSize, spatialSize, kernLength), padding = 'same', input_shape = (XDim, YDim, Samples, 1), use_bias = False)(block)\n",
        "\tblock1 = BatchNormalization()(block1)\n",
        "\tblock1 = Conv3D(D*F1, (XDim, YDim, 1), groups = F1, kernel_constraint = max_norm(1.), use_bias = False)(block1)\n",
        "\tblock1 = BatchNormalization()(block1)\n",
        "\tblock1 = Activation('elu')(block1)\n",
        "\tblock1 = AveragePooling3D((1, 1, pooling1))(block1)\n",
        "\tblock1 = dropoutType(dropoutRate)(block1)\n",
        "\n",
        "\tblock2 = Conv3D(D*F2, (1, 1, convSize), groups = F2, use_bias = False, padding = 'same')(block1)\n",
        "\tblock2 = Conv3D(F2, (1, 1, 1), use_bias = False, padding = 'same')(block2) \n",
        "\tblock2 = BatchNormalization()(block2)\n",
        "\tblock2 = Activation('elu')(block2)\n",
        "\tblock2 = AveragePooling3D((1, 1, pooling2))(block2)\n",
        "\tblock2 = dropoutType(dropoutRate)(block2)\n",
        "\n",
        "\tflatten = Flatten()(block2)\n",
        "\n",
        "\treturn Dense(nb_classes, kernel_constraint = max_norm(norm_rate))(flatten)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cmhX5jjG23O"
      },
      "source": [
        "### 2D Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkT-3q7H8jPY"
      },
      "outputs": [],
      "source": [
        "def EEGNet2D(nb_classes, Channels = 22, Samples = 240, dropoutRate = 0.5, smallKernLength = 64, mediumKernLength = 96, largeKernLength = 160, F1 = 8, D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout', pooling1=4, pooling2=8, convSize=16, branches = (\"SRF\", \"MRF\", \"LRF\")):\n",
        "  if dropoutType == 'SpatialDropout2D':\n",
        "    dropoutType = SpatialDropout2D\n",
        "  elif dropoutType == 'Dropout':\n",
        "    dropoutType = Dropout\n",
        "  else:\n",
        "    raise ValueError('dropoutType must be one of SpatialDropout2D or Dropout, passed as a string.')\n",
        "\n",
        "  input1 = Input(shape = (Channels, Samples, 1))\n",
        "\n",
        "  add_params = []\n",
        "  if (\"SRF\" in branches):\n",
        "    SRF_branch = EEGNet2D_Branch(nb_classes, Channels, Samples, dropoutRate, smallKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "    add_params.append(SRF_branch)\n",
        "  if (\"MRF\" in branches):\n",
        "    MRF_branch = EEGNet2D_Branch(nb_classes, Channels, Samples, dropoutRate, mediumKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "    add_params.append(MRF_branch)\n",
        "  if (\"LRF\" in branches):\n",
        "    LRF_branch = EEGNet2D_Branch(nb_classes, Channels, Samples, dropoutRate, largeKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "    add_params.append(LRF_branch)\n",
        "\n",
        "  if len(add_params) > 1:\n",
        "    final = Add()(add_params)\n",
        "  else:\n",
        "    final = add_params[0]\n",
        "\n",
        "  softmax = Activation('softmax', name = 'softmax')(final)\n",
        "    \n",
        "  return Model(inputs=input1, outputs=softmax)\n",
        "\n",
        "def EEGNet2D_Branch(nb_classes, Channels, Samples, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, block):\n",
        "  block1 = Conv2D(F1, (1, kernLength), padding = 'same', input_shape = (Channels, Samples, 1), use_bias = False)(block)\n",
        "  block1 = BatchNormalization()(block1)\n",
        "  # Could be swapped for depthwise conv\n",
        "  block1 = DepthwiseConv2D((Channels, 1), use_bias=False, depth_multiplier=D, depthwise_constraint=max_norm(1.))(block1)\n",
        "  #block1 = Conv2D(D*F1, (Channels, 1), groups = F1, kernel_constraint = max_norm(1.), use_bias = False)(block1)\n",
        "  block1 = BatchNormalization()(block1)\n",
        "  block1 = Activation('elu')(block1)\n",
        "  block1 = AveragePooling2D((1, pooling1))(block1)\n",
        "  block1 = dropoutType(dropoutRate)(block1)\n",
        "\n",
        "  # Both conv layers could be swapped for a separable\n",
        "  block2 = SeparableConv2D(F2, (1, convSize), use_bias=False, padding='same')(block1)\n",
        "  #block2 = Conv2D(F2, (1, convSize), groups = F2, use_bias = False, padding = 'same')(block1)\n",
        "  #block2 = Conv2D(F2, (1, 1), use_bias = False, padding = 'same')(block2) \n",
        "  block2 = BatchNormalization()(block2)\n",
        "  block2 = Activation('elu')(block2)\n",
        "  block2 = AveragePooling2D((1, pooling2))(block2)\n",
        "  block2 = dropoutType(dropoutRate)(block2)\n",
        "\n",
        "  flatten = Flatten()(block2)\n",
        "\n",
        "  return Dense(nb_classes, kernel_constraint = max_norm(norm_rate))(flatten)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWOqgBtUpMKs"
      },
      "source": [
        "### 2D Model Simple Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPNG5-eIpOUW"
      },
      "outputs": [],
      "source": [
        "def EEGNet2D_Simple(nb_classes, Channels = 22, Samples = 240, dropoutRate = 0.5, smallKernLength = 64, mediumKernLength = 96, largeKernLength = 160, F1 = 8, D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout', pooling1=4, pooling2=8, convSize=16, branches = (\"SRF\", \"MRF\", \"LRF\")):\n",
        "  if dropoutType == 'SpatialDropout2D':\n",
        "    dropoutType = SpatialDropout2D\n",
        "  elif dropoutType == 'Dropout':\n",
        "    dropoutType = Dropout\n",
        "  else:\n",
        "    raise ValueError('dropoutType must be one of SpatialDropout2D or Dropout, passed as a string.')\n",
        "\n",
        "  input1 = Input(shape = (Channels, Samples, 1))\n",
        "\n",
        "  add_params = []\n",
        "  if (\"SRF\" in branches):\n",
        "    SRF_branch = EEGNet2D_Simple_Branch(nb_classes, Channels, Samples, dropoutRate, smallKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "    add_params.append(SRF_branch)\n",
        "  if (\"MRF\" in branches):\n",
        "    MRF_branch = EEGNet2D_Simple_Branch(nb_classes, Channels, Samples, dropoutRate, mediumKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "    add_params.append(MRF_branch)\n",
        "  if (\"LRF\" in branches):\n",
        "    LRF_branch = EEGNet2D_Simple_Branch(nb_classes, Channels, Samples, dropoutRate, largeKernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, input1)\n",
        "    add_params.append(LRF_branch)\n",
        "\n",
        "  if len(add_params) > 1:\n",
        "    branch_add = Add()(add_params)\n",
        "  else:\n",
        "    branch_add = add_params[0]\n",
        "\n",
        "  block = AveragePooling2D((1, pooling1), name=\"Average_Pooling_1\")(branch_add)\n",
        "  block = dropoutType(dropoutRate)(block)\n",
        "  block = SeparableConv2D(F2, (1, convSize), use_bias=False, padding='same')(block)\n",
        "  block = BatchNormalization()(block)\n",
        "  block = Activation('elu')(block)\n",
        "  block = AveragePooling2D((1, pooling2))(block)\n",
        "  block = dropoutType(dropoutRate)(block)\n",
        "  block = Flatten()(block)\n",
        "  block = Dense(nb_classes, kernel_constraint = max_norm(norm_rate))(block)\n",
        "\n",
        "  softmax = Activation('softmax', name = 'softmax')(block)\n",
        "    \n",
        "  return Model(inputs=input1, outputs=softmax)\n",
        "\n",
        "def EEGNet2D_Simple_Branch(nb_classes, Channels, Samples, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType, pooling1, pooling2, convSize, block):\n",
        "  block1 = Conv2D(F1, (1, kernLength), padding = 'same', input_shape = (Channels, Samples, 1), use_bias = False)(block)\n",
        "  block1 = BatchNormalization()(block1)\n",
        "  # Could be swapped for depthwise conv\n",
        "  block1 = DepthwiseConv2D((Channels, 1), use_bias=False, depth_multiplier=D, depthwise_constraint=max_norm(1.))(block1)\n",
        "  #block1 = Conv2D(D*F1, (Channels, 1), groups = F1, kernel_constraint = max_norm(1.), use_bias = False)(block1)\n",
        "  block1 = BatchNormalization()(block1)\n",
        "  block1 = Activation('elu')(block1)\n",
        "\n",
        "  return block1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiKm3wozCk0m"
      },
      "source": [
        "## Model Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ku91vpCCovz"
      },
      "source": [
        "### 3D Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fGWaNNwCnvo"
      },
      "outputs": [],
      "source": [
        "def build_3d_model(hp):\n",
        "  N = NUM_CLASSES\n",
        "  Samples = DEFAULT_SAMPLES\n",
        "  B = BRANCHES\n",
        "  if (DROPOUT_RATE_3D is None):\n",
        "    DR = hp.Float('Dropout Rate', 0.001, 0.999, sampling='linear')\n",
        "  else:\n",
        "    DR = DROPOUT_RATE_3D\n",
        "  if (SRF_3D is None):\n",
        "    SKL = hp.Int('Small Kernel Length', 16, 64)\n",
        "  else:\n",
        "    SKL = SRF_3D\n",
        "  if (MRF_3D is None):\n",
        "    MKL = hp.Int('Medium Kernel Length', 64, 128)\n",
        "  else:\n",
        "    MKL = MRF_3D\n",
        "  if (LRF_3D is None):\n",
        "    LKL = hp.Int('Large Kernel Length', 128, 192)\n",
        "  else:\n",
        "    LRL = LRF_3D\n",
        "  if (F1_3D is None):\n",
        "    F1 = hp.Int('Filter 1', 2, 16)\n",
        "  else:\n",
        "    F1 = F1_3D\n",
        "  if (D_3D is None):\n",
        "    D = hp.Int('Depth', 2, 4)\n",
        "  else:\n",
        "    D = D_3D\n",
        "  if (F2_3D is None):\n",
        "    F2 = hp.Int('Filter 2', 0, 4)\n",
        "  else:\n",
        "    F2 = F2_3D\n",
        "  if (NORM_RATE_3D is None):\n",
        "    NR = hp.Float('Normalization Rate', 0, 0.999, sampling='linear')\n",
        "  else:\n",
        "    NR = NORM_RATE_3D\n",
        "  if (DROPOUT_TYPE_3D is None):\n",
        "    DT = hp.Choice('Dropout Type', ('Dropout', 'SpatialDropout3D'))\n",
        "  else:\n",
        "    DT = DROPOUT_TYPE_3D\n",
        "  if (SPATIAL_SIZE_3D is None):\n",
        "    SS = hp.Int('Spatial Size', 1, 6)\n",
        "  else:\n",
        "    SS = SPATIAL_SIZE_3D\n",
        "  if (POOLING_1_3D is None):\n",
        "    P1 = hp.Int('Pooling 1', 2, 8)\n",
        "  else:\n",
        "    P1 = POOLING_1_3D\n",
        "  if (CONV_SIZE_3D is None):\n",
        "    CS = hp.Int('Convolution Size', 4, 32)\n",
        "  else:\n",
        "    CS = CONV_SIZE_3D\n",
        "  if (POOLING_2_3D is None):\n",
        "    P2 = hp.Int('Pooling 2', 2, 8)\n",
        "  else:\n",
        "    P2 = POOLING_2_3D\n",
        "  if (INIT_LR is None):\n",
        "    LR = hp.Float('Learning Rate', 0.000001, 0.1, sampling='log')\n",
        "  else:\n",
        "    LR = INIT_LR\n",
        "\n",
        "  model = EEGNet3D(N, Samples=Samples, dropoutRate=DR, smallKernLength=SKL, mediumKernLength=MKL, largeKernLength=LKL, F1=F1, F2=F2, D=D, norm_rate=NR, dropoutType=DT, spatialSize=SS, pooling1=P1, pooling2=P2, convSize=CS, branches=B)\n",
        "  Opt = OPTIMIZER(LR)\n",
        "  model.compile(loss=LOSS_FUNCTION, optimizer=Opt, metrics=METRICS)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFboS6k-CsbZ"
      },
      "source": [
        "### 2D Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FQrNPB2Ctn9"
      },
      "outputs": [],
      "source": [
        "def build_2d_model(hp):\n",
        "  N = NUM_CLASSES\n",
        "  Samples = DEFAULT_SAMPLES\n",
        "  B = BRANCHES\n",
        "  if (DROPOUT_RATE_2D is None):\n",
        "    DR = hp.Float('Dropout Rate', 0.001, 0.999, sampling='linear')\n",
        "  else:\n",
        "    DR = DROPOUT_RATE_2D\n",
        "  if (\"SRF\" in BRANCHES):\n",
        "    if (SRF_2D is None):\n",
        "      SKL = hp.Int('Small Kernel Length', 2, 64)\n",
        "    else:\n",
        "      SKL = SRF_2D\n",
        "  if (\"MRF\" in BRANCHES):\n",
        "    if (MRF_2D is None):\n",
        "      MKL = hp.Int('Medium Kernel Length', 64, 128)\n",
        "    else:\n",
        "      MKL = MRF_2D\n",
        "  if (\"LRF\" in BRANCHES):\n",
        "    if (LRF_2D is None):\n",
        "      LKL = hp.Int('Large Kernel Length', 128, 313)\n",
        "    else:\n",
        "      LKL = LRF_2D\n",
        "  if (F1_2D is None):\n",
        "    F1 = hp.Int('Filter 1', 2, 16)\n",
        "  else:\n",
        "    F1 = F1_2D\n",
        "  if (D_2D is None):\n",
        "    D = hp.Int('Depth', 2, 4)\n",
        "  else:\n",
        "    D = D_2D\n",
        "  if (F2_2D is None):\n",
        "    F2 = hp.Int('Filter 2', 2, 32)\n",
        "  else:\n",
        "    F2 = F2_2D\n",
        "  if (NORM_RATE_2D is None):\n",
        "    NR = hp.Float('Normalization Rate', 0, 0.999, sampling='linear')\n",
        "  else:\n",
        "    NR = NORM_RATE_2D\n",
        "  if (DROPOUT_TYPE_2D is None):\n",
        "    DT = hp.Choice('Dropout Type', ('Dropout', 'SpatialDropout2D'))\n",
        "  else:\n",
        "    DT = DROPOUT_TYPE_2D\n",
        "  if (POOLING_1_2D is None):\n",
        "    P1 = hp.Int('Pooling 1', 2, 8)\n",
        "  else:\n",
        "    P1 = POOLING_1_2D\n",
        "  if (CONV_SIZE_2D is None):\n",
        "    CS = hp.Int('Convolution Size', 4, 64)\n",
        "  else:\n",
        "    CS = CONV_SIZE_2D\n",
        "  if (POOLING_2_2D is None):\n",
        "    P2 = hp.Int('Pooling 2', 2, 8)\n",
        "  else:\n",
        "    P2 = POOLING_2_2D\n",
        "  if (INIT_LR is None):\n",
        "    LR = hp.Float('Learning Rate', 0.0001, 0.001, sampling='log')\n",
        "  else:\n",
        "    LR = INIT_LR\n",
        "\n",
        "  model = EEGNet2D_Simple(N, Samples=Samples, dropoutRate=DR, smallKernLength=SKL, mediumKernLength=MKL, largeKernLength=LKL, F1=F1, F2=F2, D=D, norm_rate=NR, dropoutType=DT, pooling1=P1, pooling2=P2, convSize=CS, branches=B)\n",
        "  Opt = OPTIMIZER(LR)\n",
        "  model.compile(loss=LOSS_FUNCTION, optimizer=Opt, metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IAM_-q3ANTr"
      },
      "source": [
        "# KerasTuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6dNZKk_AQtg"
      },
      "source": [
        "## Custom Hyper Model\n",
        "Allows for Batch Size to be learned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdwUeR0FAQRd"
      },
      "outputs": [],
      "source": [
        "class CustomHyperModel(kt.HyperModel):\n",
        "  def build(self, hp):\n",
        "    if (BATCH_SIZE is None):\n",
        "      self.BS = hp.Int('Batch Size', 4, 32)\n",
        "    else:\n",
        "      self.BS = BATCH_SIZE\n",
        "    \n",
        "    if (DIMENSION == '3D'):\n",
        "      return build_3d_model(hp)\n",
        "    return build_2d_model(hp)\n",
        "    \n",
        "  def fit(self, hp, model, *args, **kwargs):\n",
        "    return model.fit(*args, batch_size=self.BS, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5fdkk1nUHK"
      },
      "source": [
        "# Tuning Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM4sGt2LnW4X",
        "outputId": "f265c0b1-dc66-43d5-bd39-35acfd326e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 36 Complete [01h 39m 00s]\n",
            "val_Accuracy: 0.3353448212146759\n",
            "\n",
            "Best val_Accuracy So Far: 0.642241358757019\n",
            "Total elapsed time: 23h 51m 27s\n",
            "\n",
            "Search: Running Trial #37\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "19                |29                |Batch Size\n",
            "64                |64                |Small Kernel Length\n",
            "86                |70                |Medium Kernel Length\n",
            "160               |151               |Large Kernel Length\n",
            "8                 |7                 |Pooling 1\n",
            "32                |21                |Convolution Size\n",
            "4                 |8                 |Pooling 2\n",
            "0.1               |0.00019897        |Learning Rate\n",
            "\n",
            "Epoch 1/500\n",
            "182/182 [==============================] - 21s 102ms/step - loss: 1.4581 - Accuracy: 0.2633 - Precision: 0.3707 - Recall: 0.0165 - val_loss: 1.4313 - val_Accuracy: 0.2500 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
            "Epoch 2/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.4298 - Accuracy: 0.2586 - Precision: 0.2958 - Recall: 0.0061 - val_loss: 1.6897 - val_Accuracy: 0.2500 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
            "Epoch 3/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.4233 - Accuracy: 0.2638 - Precision: 0.3814 - Recall: 0.0130 - val_loss: 8.6630 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 4/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.4066 - Accuracy: 0.2959 - Precision: 0.3407 - Recall: 0.0267 - val_loss: 5.9991 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 5/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.3903 - Accuracy: 0.3084 - Precision: 0.4699 - Recall: 0.0452 - val_loss: 1.4093 - val_Accuracy: 0.2741 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
            "Epoch 6/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.3685 - Accuracy: 0.3174 - Precision: 0.4802 - Recall: 0.0632 - val_loss: 2.4540 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 7/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3555 - Accuracy: 0.3348 - Precision: 0.4838 - Recall: 0.0777 - val_loss: 3.8292 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 8/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3550 - Accuracy: 0.3559 - Precision: 0.4779 - Recall: 0.0939 - val_loss: 9.3277 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 9/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.3402 - Accuracy: 0.3504 - Precision: 0.5220 - Recall: 0.0861 - val_loss: 2.9562 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 10/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3343 - Accuracy: 0.3586 - Precision: 0.5007 - Recall: 0.1009 - val_loss: 39.5874 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 11/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3515 - Accuracy: 0.3490 - Precision: 0.4735 - Recall: 0.0957 - val_loss: 4.5008 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 12/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3231 - Accuracy: 0.3501 - Precision: 0.5255 - Recall: 0.1133 - val_loss: 4.3569 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 13/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3264 - Accuracy: 0.3516 - Precision: 0.5063 - Recall: 0.1041 - val_loss: 12.3129 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 14/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.3037 - Accuracy: 0.3672 - Precision: 0.5302 - Recall: 0.1070 - val_loss: 4.0320 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 15/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3065 - Accuracy: 0.3730 - Precision: 0.5273 - Recall: 0.1342 - val_loss: 2.5872 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 16/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.3059 - Accuracy: 0.3632 - Precision: 0.5000 - Recall: 0.1232 - val_loss: 5.1234 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 17/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2846 - Accuracy: 0.3800 - Precision: 0.5447 - Recall: 0.1432 - val_loss: 5.4359 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 18/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2570 - Accuracy: 0.3899 - Precision: 0.5722 - Recall: 0.1504 - val_loss: 18.2322 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 19/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.2693 - Accuracy: 0.3803 - Precision: 0.5726 - Recall: 0.1577 - val_loss: 33.4565 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 20/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2484 - Accuracy: 0.4003 - Precision: 0.5567 - Recall: 0.1693 - val_loss: 20.8348 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 21/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2545 - Accuracy: 0.3913 - Precision: 0.5696 - Recall: 0.1768 - val_loss: 2.1709 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 22/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2465 - Accuracy: 0.4041 - Precision: 0.5710 - Recall: 0.1655 - val_loss: 82.6590 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 23/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2247 - Accuracy: 0.4128 - Precision: 0.5624 - Recall: 0.1855 - val_loss: 41.9214 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 24/500\n",
            "182/182 [==============================] - 18s 97ms/step - loss: 1.2107 - Accuracy: 0.4325 - Precision: 0.5842 - Recall: 0.2142 - val_loss: 64.2813 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 25/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.1817 - Accuracy: 0.4548 - Precision: 0.6156 - Recall: 0.2238 - val_loss: 7.2369 - val_Accuracy: 0.2940 - val_Precision: 0.2940 - val_Recall: 0.2940\n",
            "Epoch 26/500\n",
            "182/182 [==============================] - 18s 98ms/step - loss: 1.1699 - Accuracy: 0.4632 - Precision: 0.5947 - Recall: 0.2539 - val_loss: 19.6377 - val_Accuracy: 0.2500 - val_Precision: 0.2500 - val_Recall: 0.2500\n",
            "Epoch 27/500\n",
            "116/182 [==================>...........] - ETA: 5s - loss: 1.1351 - Accuracy: 0.4932 - Precision: 0.6062 - Recall: 0.2940"
          ]
        }
      ],
      "source": [
        "from keras_tuner.tuners.bayesian import BayesianOptimization\n",
        "\n",
        "OBJECTIVE = 'val_Accuracy'\n",
        "tuner = BayesianOptimization(\n",
        "    CustomHyperModel(),\n",
        "    objective=OBJECTIVE,\n",
        "    max_trials=NUM_ITERATIONS,\n",
        "    directory=TUNING_DIRECTORY,\n",
        "    project_name='KerasTuner-Bayesian-{}{}-{}-{}-{}-{}-{}'.format(PROJECT_TAG, SUBJECT_NUM, NUM_CLASSES, MODE, DIMENSION, BRANCHED, OBJECTIVE),\n",
        "    overwrite=OVERWRITE\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "if (SEARCH):\n",
        "  tuner.search(X_train, Y_train, epochs=EPOCHS, validation_data=(X_val, Y_val), callbacks=CALLBACKS, verbose=VERBOSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i84AJ5UUe1Dl"
      },
      "outputs": [],
      "source": [
        "tuner.results_summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bBVGjRK__-nF",
        "dSTzkAUFfhso",
        "GRXrWTYxcpxj"
      ],
      "name": "KT-HPTuning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}